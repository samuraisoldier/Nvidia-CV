{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will take you through how to create your own dataset and use it to train a machine learning model to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's import the tools that we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set up acceleration using a GPU if we can (don't worry about this code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda=False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the dataset\n",
    "\n",
    "Here we will create a simple dataset \n",
    "\n",
    "We will create a folder called 'data'\n",
    "\n",
    "Inside this we will make folders that contain images of different classes, and name thos sub folders after the class of image that they contain.\n",
    "\n",
    "E.g. we could put folders full of images of cats and dogs inside the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_csv(root=data_root, out_name='labels.csv'):\n",
    "    \"\"\"This function finds images in each of the sub folders and creates a csv file that tells us which class each image belongs to\"\"\"\n",
    "      ### function code here\n",
    "\n",
    "create_csv()\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv=data_root + 'labels.csv', transform=None):\n",
    "        \"\"\"\"\"\"\n",
    "        ### read the csv\n",
    "        ### get the length of the dataset\n",
    "        ### map indices to data\n",
    "        ### define the transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return ### length of dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ### open image\n",
    "        ### get label\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing our data\n",
    "\n",
    "The model we are going to create to map our inputs to our outputs has a fixed input size, so we need to resize any images that we will pass through it.\n",
    "\n",
    "We need to make some transforms that will be called on each input, to prepare it for a forward pass through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SquareResize():\n",
    "    \"\"\"Adjust aspect ratio of image to make it square\"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple)) # assert output_size is int or tuple\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):        \n",
    "        ### resize the image\n",
    "        return image, label\n",
    "\n",
    "class ToTensor():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        ### convert to tensor\n",
    "        return torch.Tensor(image), label\n",
    "    \n",
    "ytransforms = []\n",
    "### add transforms to the list of transforms\n",
    "### compose the transforms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the dataset and the transforms to preprocess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### make the dataset\n",
    "\n",
    "data_size=len(mydataset)\n",
    "train_size = int(train_split * data_size)\n",
    "val_size = int(val_split * data_size) - train_size\n",
    "test_size = data_size - (val_size + train_size)\n",
    "train_data, val_data, test_data = torch.utils.data.random_split(mydataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To feed these datasets to our models, we can create a dataloader.\n",
    "\n",
    "A dataloader loads our examples from the datasets for us, and does some useful things for us including batching together input examples and shuffling the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model to map inputs to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class VGGClassifier(torch.nn.Module):\n",
    "    def __init__(self, out_size):\n",
    "        super().__init__()\n",
    "        ### extract the features from a pro-trained model\n",
    "        ### add our own custom layers to the model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"This function is called on the data for the forward pass\"\"\"\n",
    "         ### pass the input through the model (both pretrained part and our extra layers)\n",
    "        return x     # return the output of the model\n",
    "\n",
    "    def freeze(self):\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad=False\n",
    "\n",
    "    def unfreeze(self):\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the final function to train, and also visualise the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(epochs):\n",
    "    plt.close()\n",
    "    mymodel.train()\n",
    "    \n",
    "    bcosts = []\n",
    "    ecosts = []\n",
    "    valcosts = []\n",
    "    plt.ion()\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    ax = fig.add_subplot(121)\n",
    "    #ax1 = fig.add_subplot(132)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    \n",
    "    plt.show()\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Cost')\n",
    "\n",
    "    #ax1.set_xlabel('Batch')\n",
    "    #ax1.set_ylabel('Cost')\n",
    "\n",
    "    ax2.axis('off')\n",
    "    img_label_text = ax2.text(0, -5, '', fontsize=15)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        ecost=0\n",
    "        valcost=0\n",
    "        for i, (x, y) in enumerate(train_samples):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            x = x[:, :3, :, :]\n",
    "            print(x.shape)\n",
    "\n",
    "            ### calculate hypothesis\n",
    "            ### determine the loss\n",
    "            \n",
    "            ###zero gradients\n",
    "            ###calculate derivatives of values of filters\n",
    "            ###update parameters\n",
    "\n",
    "            bcosts.append(cost.item()/batch_size)\n",
    "            #ax1.plot(bcosts, 'b', label='Train cost')\n",
    "            #if e==0 and i==0: ax1.legend()\n",
    "            \n",
    "            y_ind=0\n",
    "            im = np.array(x[y_ind]).transpose(1, 2, 0)\n",
    "            predicted_class = id_to_classname[h.max(1)[1][y_ind].item()]\n",
    "            ax2.imshow(im)\n",
    "            img_label_text.set_text('Predicted class: '+ predicted_class)\n",
    "            \n",
    "            fig.canvas.draw()\n",
    "            ecost+=cost.item()\n",
    "        #classes_shown=set()\n",
    "        \"\"\"\n",
    "        for i, (x, y) in enumerate(val_samples):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            h = mymodel.forward(x) #calculate hypothesis\n",
    "            cost = F.cross_entropy(h, y, reduction='sum') #calculate cost\n",
    "\n",
    "            '''for y_ind, yval in enumerate(y):\n",
    "                if yval.item() not in classes_shown:\n",
    "                    classes_shown.add(yval.item())\n",
    "                    break'''\n",
    "            y_ind=0\n",
    "            im = np.array(x[y_ind]).transpose(1, 2, 0)\n",
    "            predicted_class = id_to_classname[h.max(1)[1][y_ind].item()]\n",
    "            ax2.imshow(im)\n",
    "            img_label_text.set_text('Predicted class: '+ predicted_class)\n",
    "            fig.canvas.draw()\n",
    "            \n",
    "            valcost+=cost.item()\n",
    "            \"\"\"\n",
    "        ecost/=train_size\n",
    "        #valcost/=val_size\n",
    "        ecosts.append(ecost)\n",
    "        #valcosts.append(valcost)\n",
    "        ax.plot(ecosts, 'b', label='Train cost')\n",
    "        #ax.plot(valcosts, 'r', label='Validation cost')\n",
    "        if e==0: ax.legend()\n",
    "        fig.canvas.draw()\n",
    "\n",
    "        print('Epoch', e, '\\tCost', ecost)\n",
    "        \n",
    "\n",
    "def test():\n",
    "    print('Started evaluation...')\n",
    "    ### define testing function\n",
    "    return round(correct/len(test_data), 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets actually do the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mymodel.freeze()\n",
    "train(20)\n",
    "#mymodel.unfreeze()\n",
    "#train(5)\n",
    "\n",
    "acc = test()\n",
    "print('Test accuracy: ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
